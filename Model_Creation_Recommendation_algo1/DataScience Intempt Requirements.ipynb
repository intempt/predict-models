{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dca4ed1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515c0e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This Algorithm is simply creates a prediction algorithm having a script with some logic no models involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac5122",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define pickle function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbf3d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This section is optional and is based on your preferences but for ease of use we suggest creating a function that will take care of creating the pickle file. So create once but call it anytime needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b024fc4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def save_pkl(object_to_store, name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param object_to_store: object to pickle\n",
    "    :param name: name to save pickle\n",
    "    :param path: path to save pickle\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, name), 'wb') as file:\n",
    "        pickle.dump(object_to_store, file)\n",
    "\n",
    "def local_load_pkl_model(model_name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param model_name: name of pickled model to load\n",
    "    :param path: path to the pickled model\n",
    "    :return: the pickle model\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, model_name), 'rb') as file:\n",
    "        b = pickle.load(file)\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e772a06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e759e5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fastavro import parse_schema, json_reader\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a210b5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schemas = {}\n",
    "schema = {\n",
    "    'doc': 'Article collection schema',\n",
    "    'name': 'Article',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'article_id', 'type': 'int'},\n",
    "        {'name': 'product_code', 'type': 'int'},\n",
    "        {'name': 'prod_name', 'type': 'string'},\n",
    "        {'name': 'product_type_no', 'type': 'int'},\n",
    "        {'name': 'product_type_name', 'type': 'string'},\n",
    "        {'name': 'product_group_name', 'type': 'string'},\n",
    "        {'name': 'graphical_appearance_no', 'type': 'int'},\n",
    "        {'name': 'graphical_appearance_name', 'type': 'string'},\n",
    "        {'name': 'colour_group_code', 'type': 'int'},\n",
    "        {'name': 'colour_group_name', 'type': 'string'},\n",
    "        {'name': 'perceived_colour_value_id', 'type': 'int'},\n",
    "        {'name': 'perceived_colour_value_name', 'type': 'string'},\n",
    "        {'name': 'perceived_colour_master_id', 'type': 'int'},\n",
    "        {'name': 'perceived_colour_master_name', 'type': 'string'},\n",
    "        {'name': 'department_no', 'type': 'int'},\n",
    "        {'name': 'department_name', 'type': 'string'},\n",
    "        {'name': 'index_code', 'type': 'string'},\n",
    "        {'name': 'index_name', 'type': 'string'},\n",
    "        {'name': 'index_group_no', 'type': 'int'},\n",
    "        {'name': 'index_group_name', 'type': 'string'},\n",
    "        {'name': 'section_no', 'type': 'int'},\n",
    "        {'name': 'section_name', 'type': 'string'},\n",
    "        {'name': 'garment_group_no', 'type': 'int'},\n",
    "        {'name': 'garment_group_name', 'type': 'string'},\n",
    "        {'name': 'detail_desc', 'type': 'string'},\n",
    "        {'name': 'article_url', 'type': 'string'}\n",
    "    ],\n",
    "}\n",
    "schemas['article'] = parse_schema(schema)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Customer collection schema',\n",
    "    'name': 'Customer',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'FN', 'type': 'string'},\n",
    "        {'name': 'Active', 'type': 'string'},\n",
    "        {'name': 'club_member_status', 'type': 'string'},\n",
    "        {'name': 'fashion_news_frequency', 'type': 'string'},\n",
    "        {'name': 'age', 'type': 'int'},\n",
    "        {'name': 'postal_code', 'type': 'string'}\n",
    "    ],\n",
    "}\n",
    "schemas['customer'] = parse_schema(schema)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Transaction collection schema',\n",
    "    'name': 'Transaction',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 't_dat', 'type': 'string'},\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'article_id', 'type': 'int'},\n",
    "        {'name': 'price', 'type': 'int'},\n",
    "        {'name': 'sales_channel_id', 'type': 'long'}\n",
    "    ],\n",
    "}\n",
    "schemas['transaction'] = parse_schema(schema)\n",
    "\n",
    "def load(collection):\n",
    "    records = []\n",
    "    with open('./collections/' + collection + '.json', 'r') as fo:\n",
    "        avro_reader = json_reader(fo, schemas[collection])\n",
    "        for record in avro_reader:\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "\n",
    "data = {\n",
    "    'org_id': 1,  # organization id (added by the \"loader\")\n",
    "    'article': [load('article')],  # bonuses for this user\n",
    "    'customer': [load('customer')],  # payments for this user\n",
    "    'transaction': [load('transaction')],  # games for this user\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3facc261",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create feature_names.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "162f0c0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = ['customer','transaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5543b3fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use save_pkl function to store feature_names object\n",
    "save_pkl(object_to_store = feature_names, name = \"feature_names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857f118",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create prediction.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b5f8821",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(data):\n",
    "\n",
    "    import ast\n",
    "    import pandas as pd \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pandas import DataFrame\n",
    "    \n",
    "    data = DataFrame(data)\n",
    "    # Get customer data\n",
    "    customer_df1 = data['customer'].astype(str).dropna().apply(ast.literal_eval)\n",
    "    customer_df2 = pd.concat([pd.DataFrame(x) for x in customer_df1], keys=customer_df1.index)\n",
    "    customer = data[['org_id']].join(customer_df2.reset_index(level=1, drop=True)).reset_index(drop=True)\n",
    "\n",
    "    # Get transaction data\n",
    "    transaction_df1 = data['transaction'].astype(str).dropna().apply(ast.literal_eval)\n",
    "    transaction_df2 = pd.concat([pd.DataFrame(x) for x in transaction_df1], keys=transaction_df1.index)\n",
    "    transaction = data[['org_id']].join(transaction_df2.reset_index(level=1, drop=True)).reset_index(drop=True)\n",
    "    transaction[\"t_dat\"] =  pd.to_datetime(transaction[\"t_dat\"], format=\"%Y-%m-%d\")\n",
    "    transaction[\"article_id\"] =  transaction[\"article_id\"].astype(str)\n",
    "\n",
    "    df_3w = transaction[transaction['t_dat'] >= pd.to_datetime('2020-08-31')].copy()\n",
    "    df_2w = transaction[transaction['t_dat'] >= pd.to_datetime('2020-09-07')].copy()\n",
    "    df_1w = transaction[transaction['t_dat'] >= pd.to_datetime('2020-09-15')].copy()\n",
    "    \n",
    "    purchase_dict_3w = {}\n",
    "\n",
    "    for i,x in enumerate(zip(df_3w['customer_id'], df_3w['article_id'])):\n",
    "        cust_id, art_id = x\n",
    "        if cust_id not in purchase_dict_3w:\n",
    "            purchase_dict_3w[cust_id] = {}\n",
    "\n",
    "        if art_id not in purchase_dict_3w[cust_id]:\n",
    "            purchase_dict_3w[cust_id][art_id] = 0\n",
    "\n",
    "        purchase_dict_3w[cust_id][art_id] += 1\n",
    "\n",
    "    dummy_list_3w = list((df_3w['article_id'].value_counts()).index)[:12]\n",
    "    \n",
    "    purchase_dict_2w = {}\n",
    "\n",
    "    for i,x in enumerate(zip(df_2w['customer_id'], df_2w['article_id'])):\n",
    "        cust_id, art_id = x\n",
    "        if cust_id not in purchase_dict_2w:\n",
    "            purchase_dict_2w[cust_id] = {}\n",
    "\n",
    "        if art_id not in purchase_dict_2w[cust_id]:\n",
    "            purchase_dict_2w[cust_id][art_id] = 0\n",
    "\n",
    "        purchase_dict_2w[cust_id][art_id] += 1\n",
    "\n",
    "    dummy_list_2w = list((df_2w['article_id'].value_counts()).index)[:12]\n",
    "    \n",
    "    purchase_dict_1w = {}\n",
    "\n",
    "    for i,x in enumerate(zip(df_1w['customer_id'], df_1w['article_id'])):\n",
    "        cust_id, art_id = x\n",
    "        if cust_id not in purchase_dict_1w:\n",
    "            purchase_dict_1w[cust_id] = {}\n",
    "\n",
    "        if art_id not in purchase_dict_1w[cust_id]:\n",
    "            purchase_dict_1w[cust_id][art_id] = 0\n",
    "\n",
    "        purchase_dict_1w[cust_id][art_id] += 1\n",
    "\n",
    "    dummy_list_1w = list((df_1w['article_id'].value_counts()).index)[:12]\n",
    "    \n",
    "    dummy_benchmark = customer[['customer_id']].copy()\n",
    "    \n",
    "    prediction_list = []\n",
    "\n",
    "    dummy_list = list((df_2w['article_id'].value_counts()).index)[:12]\n",
    "    dummy_pred = ' '.join(dummy_list)\n",
    "\n",
    "    for i, cust_id in enumerate(customer['customer_id'].values.reshape((-1,))):\n",
    "        if cust_id in purchase_dict_1w:\n",
    "            l = sorted((purchase_dict_1w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            if len(l)>12:\n",
    "                s = ' '.join(l[:12])\n",
    "            else:\n",
    "                s = ' '.join(l+dummy_list_1w[:(12-len(l))])\n",
    "        elif cust_id in purchase_dict_2w:\n",
    "            l = sorted((purchase_dict_2w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            if len(l)>12:\n",
    "                s = ' '.join(l[:12])\n",
    "            else:\n",
    "                s = ' '.join(l+dummy_list_2w[:(12-len(l))])\n",
    "        elif cust_id in purchase_dict_3w:\n",
    "            l = sorted((purchase_dict_3w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            if len(l)>12:\n",
    "                s = ' '.join(l[:12])\n",
    "            else:\n",
    "                s = ' '.join(l+dummy_list_3w[:(12-len(l))])\n",
    "        else:\n",
    "            s = dummy_pred\n",
    "        prediction_list.append(s)\n",
    "\n",
    "    dummy_benchmark['prediction'] = prediction_list\n",
    "    dummy_benchmark['prediction'] = dummy_benchmark['prediction'].str.split()\n",
    "    return dummy_benchmark\n",
    "\n",
    "save_pkl(object_to_store = prediction, name = \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1bd21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235d5a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fcc1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "579c49cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tedst prediction flow️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4354fb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def save_pkl(object_to_store, name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param object_to_store: object to pickle\n",
    "    :param name: name to save pickle\n",
    "    :param path: path to save pickle\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, name), 'wb') as file:\n",
    "        pickle.dump(object_to_store, file)\n",
    "\n",
    "def local_load_pkl_model(model_name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param model_name: name of pickled model to load\n",
    "    :param path: path to the pickled model\n",
    "    :return: the pickle model\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, model_name), 'rb') as file:\n",
    "        b = pickle.load(file)\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61688b6b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e245285",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fastavro import parse_schema, json_reader\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56f0e895",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading collection features: ['customer', 'transaction']\n"
     ]
    }
   ],
   "source": [
    "feature_names = local_load_pkl_model(model_name=f'feature_names')\n",
    "print(f'Loading collection features: {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e5660e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schemas = {}\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Customer collection schema',\n",
    "    'name': 'Customer',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'FN', 'type': 'string'},\n",
    "        {'name': 'Active', 'type': 'string'},\n",
    "        {'name': 'club_member_status', 'type': 'string'},\n",
    "        {'name': 'fashion_news_frequency', 'type': 'string'},\n",
    "        {'name': 'age', 'type': 'int'},\n",
    "        {'name': 'postal_code', 'type': 'string'}\n",
    "    ],\n",
    "}\n",
    "schemas['customer'] = parse_schema(schema)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Transaction collection schema',\n",
    "    'name': 'Transaction',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 't_dat', 'type': 'string'},\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'article_id', 'type': 'int'},\n",
    "        {'name': 'price', 'type': 'int'},\n",
    "        {'name': 'sales_channel_id', 'type': 'long'}\n",
    "    ],\n",
    "}\n",
    "schemas['transaction'] = parse_schema(schema)\n",
    "\n",
    "def load(collection):\n",
    "    records = []\n",
    "    with open('./collections/' + collection + '.json', 'r') as fo:\n",
    "        avro_reader = json_reader(fo, schemas[collection])\n",
    "        for record in avro_reader:\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "\n",
    "data = {\n",
    "    'org_id': 1,  # organization id (added by the \"loader\")\n",
    "    'customer': [load('customer')],  # payments for this user\n",
    "    'transaction': [load('transaction')],  # games for this user\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09fd9d48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction function\n",
      "Supply predcition with collection data\n"
     ]
    }
   ],
   "source": [
    "prediction_function = local_load_pkl_model(model_name=f'prediction')\n",
    "print('Loading prediction function')\n",
    "\n",
    "print('Supply predcition with collection data')\n",
    "prediction = prediction_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "862860c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>[568601043, 448509014, 372860001, 579541001, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>[448509014, 372860001, 673677002, 536139068, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>[448509014, 372860001, 673677002, 536139068, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>[448509014, 372860001, 673677002, 536139068, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>[448509014, 372860001, 673677002, 536139068, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id                                         prediction\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  [568601043, 448509014, 372860001, 579541001, 6...\n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...  [448509014, 372860001, 673677002, 536139068, 2...\n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  [448509014, 372860001, 673677002, 536139068, 2...\n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...  [448509014, 372860001, 673677002, 536139068, 2...\n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  [448509014, 372860001, 673677002, 536139068, 2..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4720fa",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bf623de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad056c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The final step would be to provide us with all the libraries that those pkl objects are using. So for example in the model code cell you are importing **lightgbm** so we will need to know about this library. The **requirements.txt** correspond to used libraries and packages for your enviornment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fac158",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "lightgbm <br>\n",
    "scikit-learn <br>\n",
    "pandas <br>\n",
    "dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672aece",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**So for the above examples it's pretty straight forward and the contents of this file are the above 3 libraries.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c3d83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e555e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that if you have some version dependency of a specific library make sure to define the specific version\n",
    "required. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76863f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "lightgbm == 3.3.2 <br>\n",
    "scikit-learn == 0.24.2 <br>\n",
    "pandas == 1.3.4 <br>\n",
    "dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616fa95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  IMP Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814df0fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Practical recommender systems need be periodically retrained to refresh the model with new interaction data. To pursue high model fidelity, it is usually desirable to retrain the model on both historical and new data, since it can account for both long-term and short-term user preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f98615",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560064b4",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac669406",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}