{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dca4ed1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515c0e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This Algorithm creates mapping and a model together with a prediction function that are needed when calling the prediction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b024fc4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def save_pkl(object_to_store, name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param object_to_store: object to pickle\n",
    "    :param name: name to save pickle\n",
    "    :param path: path to save pickle\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, name), 'wb') as file:\n",
    "        pickle.dump(object_to_store, file)\n",
    "\n",
    "def local_load_pkl_model(model_name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param model_name: name of pickled model to load\n",
    "    :param path: path to the pickled model\n",
    "    :return: the pickle model\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, model_name), 'rb') as file:\n",
    "        b = pickle.load(file)\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e772a06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e759e5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fastavro import parse_schema, json_reader\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a210b5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schemas = {}\n",
    "schema = {\n",
    "    'doc': 'Article collection schema',\n",
    "    'name': 'Article',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'article_id', 'type': 'int'},\n",
    "        {'name': 'product_code', 'type': 'int'},\n",
    "        {'name': 'prod_name', 'type': 'string'},\n",
    "        {'name': 'product_type_no', 'type': 'int'},\n",
    "        {'name': 'product_type_name', 'type': 'string'},\n",
    "        {'name': 'product_group_name', 'type': 'string'},\n",
    "        {'name': 'graphical_appearance_no', 'type': 'int'},\n",
    "        {'name': 'graphical_appearance_name', 'type': 'string'},\n",
    "        {'name': 'colour_group_code', 'type': 'int'},\n",
    "        {'name': 'colour_group_name', 'type': 'string'},\n",
    "        {'name': 'perceived_colour_value_id', 'type': 'int'},\n",
    "        {'name': 'perceived_colour_value_name', 'type': 'string'},\n",
    "        {'name': 'perceived_colour_master_id', 'type': 'int'},\n",
    "        {'name': 'perceived_colour_master_name', 'type': 'string'},\n",
    "        {'name': 'department_no', 'type': 'int'},\n",
    "        {'name': 'department_name', 'type': 'string'},\n",
    "        {'name': 'index_code', 'type': 'string'},\n",
    "        {'name': 'index_name', 'type': 'string'},\n",
    "        {'name': 'index_group_no', 'type': 'int'},\n",
    "        {'name': 'index_group_name', 'type': 'string'},\n",
    "        {'name': 'section_no', 'type': 'int'},\n",
    "        {'name': 'section_name', 'type': 'string'},\n",
    "        {'name': 'garment_group_no', 'type': 'int'},\n",
    "        {'name': 'garment_group_name', 'type': 'string'},\n",
    "        {'name': 'detail_desc', 'type': 'string'},\n",
    "        {'name': 'article_url', 'type': 'string'}\n",
    "    ],\n",
    "}\n",
    "schemas['article'] = parse_schema(schema)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Customer collection schema',\n",
    "    'name': 'Customer',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'FN', 'type': 'string'},\n",
    "        {'name': 'Active', 'type': 'string'},\n",
    "        {'name': 'club_member_status', 'type': 'string'},\n",
    "        {'name': 'fashion_news_frequency', 'type': 'string'},\n",
    "        {'name': 'age', 'type': 'int'},\n",
    "        {'name': 'postal_code', 'type': 'string'}\n",
    "    ],\n",
    "}\n",
    "schemas['customer'] = parse_schema(schema)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Transaction collection schema',\n",
    "    'name': 'Transaction',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 't_dat', 'type': 'string'},\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'article_id', 'type': 'int'},\n",
    "        {'name': 'price', 'type': 'int'},\n",
    "        {'name': 'sales_channel_id', 'type': 'long'}\n",
    "    ],\n",
    "}\n",
    "schemas['transaction'] = parse_schema(schema)\n",
    "\n",
    "def load(collection):\n",
    "    records = []\n",
    "    with open('./collections/' + collection + '.json', 'r') as fo:\n",
    "        avro_reader = json_reader(fo, schemas[collection])\n",
    "        for record in avro_reader:\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "\n",
    "data = {\n",
    "    'org_id': 1,  # organization id (added by the \"loader\")\n",
    "    'article': [load('article')],  # bonuses for this user\n",
    "    'customer': [load('customer')],  # payments for this user\n",
    "    'transaction': [load('transaction')],  # games for this user\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59d1f3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680407a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Import LightFM's evaluation metrics\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "%matplotlib inline\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7b28dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = DataFrame(data)\n",
    "# Get customer data\n",
    "customer_df1 = data['customer'].astype(str).dropna().apply(ast.literal_eval)\n",
    "customer_df2 = pd.concat([pd.DataFrame(x) for x in customer_df1], keys=customer_df1.index)\n",
    "customer = data[['org_id']].join(customer_df2.reset_index(level=1, drop=True)).reset_index(drop=True)\n",
    "\n",
    "# Get article data\n",
    "article_df1 = data['article'].astype(str).dropna().apply(ast.literal_eval)\n",
    "article_df2 = pd.concat([pd.DataFrame(x) for x in article_df1], keys=article_df1.index)\n",
    "article = data[['org_id']].join(article_df2.reset_index(level=1, drop=True)).reset_index(drop=True)\n",
    "article[\"article_id\"] =  article[\"article_id\"].astype(str)\n",
    "\n",
    "# Get transaction data\n",
    "transaction_df1 = data['transaction'].astype(str).dropna().apply(ast.literal_eval)\n",
    "transaction_df2 = pd.concat([pd.DataFrame(x) for x in transaction_df1], keys=transaction_df1.index)\n",
    "transaction = data[['org_id']].join(transaction_df2.reset_index(level=1, drop=True)).reset_index(drop=True)\n",
    "transaction[\"t_dat\"] =  pd.to_datetime(transaction[\"t_dat\"])\n",
    "transaction[\"article_id\"] =  transaction[\"article_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c7132",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Merge articles with transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc920dd9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 10001, Number of topics: 50000.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset.fit(users=customer['customer_id'].unique(), \n",
    "            items=article['article_id'].unique())\n",
    "\n",
    "num_users, num_topics = dataset.interactions_shape()\n",
    "print(f'Number of users: {num_users}, Number of topics: {num_topics}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563e39e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 50000) (10001, 50000)\n"
     ]
    }
   ],
   "source": [
    "#train_set = train[(train.t_dat>='2020-8-26')&(train.t_dat<='2020-9-15')]\n",
    "train_set = transaction[transaction.t_dat<='2020-9-15']\n",
    "val_set = transaction[(transaction.t_dat>='2020-9-16')&(transaction.t_dat<='2020-9-22')]\n",
    "\n",
    "(interactions, weights) = dataset.build_interactions(train_set.iloc[:, 2:4].values)\n",
    "(val_interactions, val_weights) = dataset.build_interactions(val_set.iloc[:, 2:4].values)\n",
    "print(interactions.shape, val_interactions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13457ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f9e9edb4ac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default number of recommendations\n",
    "K = 10\n",
    "EPOCHS = 1\n",
    "\n",
    "# model learning rate\n",
    "LEARNING_RATE = 0.25\n",
    "# no of latent factors\n",
    "NO_COMPONENTS = 20\n",
    "\n",
    "# no of threads to fit model\n",
    "NO_THREADS = 32\n",
    "# regularisation for both user and item features\n",
    "ITEM_ALPHA=1e-6\n",
    "USER_ALPHA=1e-6\n",
    "\n",
    "\n",
    "model = LightFM(loss='warp', no_components=NO_COMPONENTS, \n",
    "                 learning_rate=LEARNING_RATE,                 \n",
    "                 random_state=np.random.RandomState(SEED))\n",
    "model.fit(interactions=interactions, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d4b1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87ee30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac6af2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3facc261",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create feature_names.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162f0c0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = ['customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5543b3fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use save_pkl function to store feature_names object\n",
    "save_pkl(object_to_store = feature_names, name = \"feature_names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4456d57d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create light_fm.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af729ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "light_fm = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab404ea8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use save_pkl function to store feature_names object\n",
    "save_pkl(object_to_store = light_fm, name = \"light_fm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac79ede",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create mappings.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30eeecd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mapping = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1c460f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use save_pkl function to store feature_names object\n",
    "save_pkl(object_to_store = mapping, name = \"mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857f118",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create prediction.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5f8821",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(data, mappings, light_fm):\n",
    "    \n",
    "    import ast\n",
    "    import pandas as pd\n",
    "    from pandas import DataFrame\n",
    "    import numpy as np\n",
    "    import tqdm\n",
    "    \n",
    "    K = 10\n",
    "\n",
    "    data = DataFrame(data)\n",
    "    # Get customer data\n",
    "    customer_df1 = data['customer'].astype(str).dropna().apply(ast.literal_eval)\n",
    "    customer_df2 = pd.concat([pd.DataFrame(x) for x in customer_df1], keys=customer_df1.index)\n",
    "    customer = data[['org_id']].join(customer_df2.reset_index(level=1, drop=True)).reset_index(drop=True)\n",
    "    \n",
    "    #Get the mappings\n",
    "    '''\n",
    "    uid = mapping from customer_id to model equivalent user_id\n",
    "    iid = mapping from article_id to  model equivalent article_id\n",
    "    '''\n",
    "    uid_map, ufeature_map, iid_map, ifeature_map = mappings.mapping() \n",
    "    '''\n",
    "    create inverse mappings\n",
    "    '''\n",
    "    inv_uid_map = {v:k for k, v in uid_map.items()}\n",
    "    inv_iid_map = {v:k for k, v in iid_map.items()}\n",
    "\n",
    "    #convert submission user_id and article_id to model equivalent user_id and article_id\n",
    "\n",
    "    test_X = customer.customer_id.values.tolist()\n",
    "    lfn_user = lambda x: uid_map[x]\n",
    "    \n",
    "    #check if customers are missing from the dataset mappings\n",
    "    \n",
    "    set1 = set(test_X)\n",
    "    set2 = set(uid_map.keys())\n",
    "\n",
    "    missing_list = list(sorted(set1 - set2))\n",
    "    \n",
    "    for missing in missing_list:\n",
    "        print(missing)\n",
    "        test_X.remove(missing)\n",
    "    \n",
    "    test_X_m = [lfn_user(tx) for tx in test_X]\n",
    "    print(len(test_X_m))\n",
    "\n",
    "\n",
    "    customer_ids = []\n",
    "    preds = []\n",
    "\n",
    "    for usr_ in tqdm.tqdm(test_X_m, total = len(test_X_m)):\n",
    "        m_opt = light_fm.predict(np.array([usr_] * len(iid_map)), np.array(list(iid_map.values())))\n",
    "        pred = np.argsort(-m_opt)[:K]\n",
    "        customer_ids.append(inv_uid_map[usr_])\n",
    "        preds.append(' '.join([inv_iid_map[p] for p in pred]).strip())\n",
    "        #break\n",
    "\n",
    "    # Add customers that where missing from the dataset mapping \n",
    "    for usr_ in missing_list:\n",
    "        customer_ids.append(usr_)\n",
    "        preds.append('Missing from Dataset Mapping')\n",
    "    \n",
    "    customer_ids = np.array(customer_ids).reshape(-1, 1)\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "\n",
    "    final_preds = pd.DataFrame(data=np.concatenate((customer_ids, preds), axis=1).reshape(-1, 2), columns=['customer_id', 'prediction'])\n",
    "    return final_preds\n",
    "\n",
    "save_pkl(object_to_store = prediction, name = \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235d5a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fcc1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "579c49cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predictions ☂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec95693b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def save_pkl(object_to_store, name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param object_to_store: object to pickle\n",
    "    :param name: name to save pickle\n",
    "    :param path: path to save pickle\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, name), 'wb') as file:\n",
    "        pickle.dump(object_to_store, file)\n",
    "\n",
    "def local_load_pkl_model(model_name: str, path: str = './'):\n",
    "    \"\"\"\n",
    "    :param model_name: name of pickled model to load\n",
    "    :param path: path to the pickled model\n",
    "    :return: the pickle model\n",
    "    \"\"\"\n",
    "    with open('{}/{}.pkl'.format(path, model_name), 'rb') as file:\n",
    "        b = pickle.load(file)\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e0e72",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad27a88b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fastavro import parse_schema, json_reader\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56f0e895",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading collection features: ['customer']\n"
     ]
    }
   ],
   "source": [
    "feature_names = local_load_pkl_model(model_name=f'feature_names')\n",
    "print(f'Loading collection features: {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e5660e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "schemas = {}\n",
    "\n",
    "schema = {\n",
    "    'doc': 'Customer collection schema',\n",
    "    'name': 'Customer',\n",
    "    'namespace': 'test',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'customer_id', 'type': 'string'},\n",
    "        {'name': 'FN', 'type': 'string'},\n",
    "        {'name': 'Active', 'type': 'string'},\n",
    "        {'name': 'club_member_status', 'type': 'string'},\n",
    "        {'name': 'fashion_news_frequency', 'type': 'string'},\n",
    "        {'name': 'age', 'type': 'int'},\n",
    "        {'name': 'postal_code', 'type': 'string'}\n",
    "    ],\n",
    "}\n",
    "schemas['customer'] = parse_schema(schema)\n",
    "\n",
    "def load(collection):\n",
    "    records = []\n",
    "    with open('./collections/' + collection + '.json', 'r') as fo:\n",
    "        avro_reader = json_reader(fo, schemas[collection])\n",
    "        for record in avro_reader:\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "\n",
    "data = {\n",
    "    'org_id': 1,  # organization id (added by the \"loader\")\n",
    "    'customer': [load('customer')],  # payments for this user\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38eb9213",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Light FM model: <lightfm.lightfm.LightFM object at 0x7f9de85a34c0>\n"
     ]
    }
   ],
   "source": [
    "light_fm = local_load_pkl_model(model_name=f'light_fm')\n",
    "print(f'Loading Light FM model: {light_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91012089",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data mapping: <lightfm.data.Dataset object at 0x7f9e9ecd0f10>\n"
     ]
    }
   ],
   "source": [
    "mapping = local_load_pkl_model(model_name=f'mapping')\n",
    "print(f'Loading data mapping: {mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97fd9452",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction function\n"
     ]
    }
   ],
   "source": [
    "prediction_function = local_load_pkl_model(model_name=f'prediction')\n",
    "print('Loading prediction function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09fd9d48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supply predcition function with collection data\n",
      "10001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10001/10001 [02:00<00:00, 82.80it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Supply predcition function with collection data')\n",
    "prediction = prediction_function(data, mapping, light_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862860c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>689390003 668241001 594541008 611415026 694497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>577034001 582480004 678571009 619229003 590221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>577034001 582480004 619229003 678571009 590221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>675852002 584198001 491912025 599713005 523404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>623765033 567813002 599713005 612800020 656121...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id                                         prediction\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  689390003 668241001 594541008 611415026 694497...\n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...  577034001 582480004 678571009 619229003 590221...\n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  577034001 582480004 619229003 678571009 590221...\n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...  675852002 584198001 491912025 599713005 523404...\n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  623765033 567813002 599713005 612800020 656121..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4720fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bf623de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad056c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The final step would be to provide us with all the libraries that those pkl objects are using. So for example in the model code cell you are importing **lightgbm** so we will need to know about this library. The **requirements.txt** correspond to used libraries and packages for your enviornment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fac158",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "lightgbm <br>\n",
    "scikit-learn <br>\n",
    "pandas <br>\n",
    "dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672aece",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**So for the above examples it's pretty straight forward and the contents of this file are the above 3 libraries.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c3d83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e555e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that if you have some version dependency of a specific library make sure to define the specific version\n",
    "required. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76863f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "lightgbm == 3.3.2 <br>\n",
    "scikit-learn == 0.24.2 <br>\n",
    "pandas == 1.3.4 <br>\n",
    "dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616fa95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  IMP Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814df0fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Practical recommender systems need be periodically retrained to refresh the model with new interaction data. To pursue high model fidelity, it is usually desirable to retrain the model on both historical and new data, since it can account for both long-term and short-term user preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f98615",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560064b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}